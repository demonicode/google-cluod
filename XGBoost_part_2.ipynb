{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part, we use the result of the grid search to finally set the best values of hyper-parameter and see what score they give us. Also, we try that model on Kaggle server also for curiosity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the prepprocessing of the data as done on the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demonicode/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the  necessary modules\n",
    "import pandas\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import zipfile\n",
    "from sklearn import cross_validation, metrics\n",
    "\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"train.csv.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "#loading train data to be used to create submission file to submission file to be used for kaggle submission\n",
    "zip_ref2 = zipfile.ZipFile(\"test.csv.zip\", 'r')\n",
    "zip_ref2.extractall()\n",
    "zip_ref2.close()\n",
    "\n",
    "\n",
    "train_data = pandas.read_csv(\"train.csv\")\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "test_data['loss'] = np.nan\n",
    "\n",
    "\n",
    "joined = pandas.concat([train_data, test_data],ignore_index = True)\n",
    "del train_data,test_data\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]\n",
    "\n",
    "for column in cat_feature:\n",
    "        joined[column] = pandas.factorize(joined[column].values, sort=True)[0]\n",
    "        \n",
    "del cat_feature\n",
    "\n",
    "\n",
    "\n",
    "train_data = joined[joined['loss'].notnull()]\n",
    "test_data = joined[joined['loss'].isnull()]\n",
    "del joined\n",
    "\n",
    "ids = test_data['id']\n",
    "\n",
    "\n",
    "shift = 200\n",
    "train_data[\"loss\"] = np.log(train_data[\"loss\"]+shift)\n",
    "target = train_data['loss']\n",
    "train_data.drop(['id','loss'],1,inplace=True)\n",
    "test_data.drop(['id','loss'],1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after our model is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2016\n",
    "    params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.01,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 1,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    xgtrain = xgb.DMatrix(X, label=y)\n",
    "    xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)\n",
    "\n",
    "    prediction = np.exp(model.predict(xgtest)) - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "    submission['loss'] = prediction\n",
    "    submission['id'] = ids\n",
    "    submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
